{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию, которая принимает ввод от пользователя и возвращает ответ от модели GPT, а также подсчитывает количество токенов. Ваша функция должна быть способна обрабатывать любой ввод пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install openai langchain-core langchain-openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:··········\n"
     ]
    }
   ],
   "source": [
    "# если вы не используете colab secrets\n",
    "import getpass\n",
    "import openai\n",
    "import os\n",
    "# Получение ключа API от пользователя и установка его как переменной окружения\n",
    "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запустите эту ячейку, если используете секретный ключ в колабе\n",
    "import openai\n",
    "import os\n",
    "from google.colab import userdata\n",
    "key = userdata.get('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from  langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt_response_and_token_count(user_input):\n",
    "    # Инициализация клиента OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "    # Ваше решение далее\n",
    "    messages = [\n",
    "      HumanMessage(content=f\"{user_input}\")\n",
    "    ]\n",
    "\n",
    "  chat = ChatOpenAI(temperature=0)\n",
    "  chat.get_num_tokens_from_messages(messages)\n",
    "\n",
    "print(\"Ответ GPT:\", response)\n",
    "print(\"Количество токенов:\", token_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "    encoding = tiktoken.encoding_for_model()\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def get_gpt_response_and_token_count(user_input):\n",
    "    client = openai.ChatCompletion.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": user_input}]\n",
    "    )\n",
    "\n",
    "    response_text = client[\"choices\"][0][\"message\"][\"content\"]\n",
    "    input_tokens = count_tokens(user_input)\n",
    "    output_tokens = count_tokens(response_text)\n",
    "    total_tokens = input_tokens + output_tokens\n",
    "\n",
    "    return response_text, total_tokens\n",
    "\n",
    "user_input = input(\"Введите запрос: \")\n",
    "response, token_count = get_gpt_response_and_token_count(user_input)\n",
    "print(\"Ответ GPT:\", response)\n",
    "print(\"Количество токенов:\", token_count)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
